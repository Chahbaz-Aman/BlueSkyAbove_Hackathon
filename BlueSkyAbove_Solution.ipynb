{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue Sky Above: Pollution estimation using hyper-spectral satellite imagery and maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission for the Blue Sky Challenge hosted by IEEE Young Professionals. <br>\n",
    "Theme:** Blue Sky Above <br>\n",
    "**Team:** Diyaz\n",
    "\n",
    "**Solution overview:**<br>\n",
    ">The goal is to estimate NO2 levels at a place at a specified time using satellite measurements from upto 7 prior days and map data.\n",
    "This must be done using minimal satellite data while maximizing accuracy. Furthermore, it needs to minimize data download requirement and processing needs to be able to run in a mobile device. <br>\n",
    "\n",
    "> Our solution assumes that 7 days of satellite data is stored in a server which takes mobile app requests through an API.<br>\n",
    "The server side program uses an autoencoder network to compress the <u> most recent satellite data</u>  for the mobile user's location and time which is then downloaded by the app. <br>\n",
    "Further, the app downloads a map centred at the location of the phone of an area of dimensions 7x7 sq.km to extract land-use features.<br>\n",
    "This gathered data along with the time difference between the satellite measurement and current time is fed to the app's NO2 estimator. <br>\n",
    "The NO2 estimator is a Random Forest Regressor using just 10 trees of depth 20 - this can execute on all modern mobile phones. \n",
    "The estimator processes the data and provides the current NO2 estimate in Âµg/m^3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Necessary Libraries/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:50.874881Z",
     "start_time": "2019-06-16T14:44:38.616867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:50.874881Z",
     "start_time": "2019-06-16T14:44:38.616867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install smopy\n",
    "!{sys.executable} -m pip install sentinelsat\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m pip install geopy\n",
    "!{sys.executable} -m pip install xarray\n",
    "!{sys.executable} -m pip install tqdm\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "clear_output(wait = True)\n",
    "print('All necessary modules are installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Code timing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "# (Code provided in the BlueSkyAbove getting-started notebook.)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "\n",
    "def TicTocGenerator():\n",
    "    # Generator that returns time differences\n",
    "    ti = 0           # initial time\n",
    "    tf = time.time() # final time\n",
    "    while True:\n",
    "        ti = tf\n",
    "        tf = time.time()\n",
    "        yield tf-ti # returns the time difference\n",
    "\n",
    "TicToc = TicTocGenerator() # create an instance of the TicTocGen generator\n",
    "\n",
    "# This will be the main function through which we define both tic() and toc()\n",
    "def toc(tempBool=True):\n",
    "    # Prints the time difference yielded by generator instance TicToc\n",
    "    tempTimeInterval = next(TicToc)\n",
    "    if tempBool:\n",
    "        print( \"Elapsed time: %f seconds.\\n\" %tempTimeInterval )\n",
    "\n",
    "def tic():\n",
    "    # Records a time in TicToc, marks the beginning of a time interval\n",
    "    toc(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T14:44:50.874881Z",
     "start_time": "2019-06-16T14:44:38.616867Z"
    },
    "tags": []
   },
   "source": [
    "### Downloading the hyperspectral satellite data\n",
    "For reliable functioning of the NO2 estimation model, satellite data upto 7 days prior to the time of estimation needs to be available.\n",
    "The following code segment will use the SentinelAPI to get information about the available data products for the required location during the a specified date range. <br> **Note:** When prompted to enter the 'start date', enter a date at least 3 days prior to the date when the first estimation is required.\n",
    "<br>_Satellite data will be downloaded and stored in the folder data/L2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing with default specifications...\n",
      "satellite_data_filenames.csv has been updated.\n"
     ]
    }
   ],
   "source": [
    "import Sentinel5PDataDownload as s5pdd\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "# By default satellite data is downloaded for the following specifications:\n",
    "# >>> Dates: 25-03-2021 to 05-04-2021\n",
    "# >>> Area: Area: enclosed in latitudes: [51.25,51.75] and longitudes: [-0.6, -0.28]\n",
    "# (These are the same specifications as provided in the BlueSkyAbove getting-started notebook.)\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "startdate, enddate, LatMin, LatMax, LngMin, LngMax = '20210325', '20210405', 51.25, 51.75, -0.6, 0.28\n",
    "\n",
    "c = input('Enter new specifications (Y/N)?')\n",
    "\n",
    "if c in ['y','Y','yes','Yes']:\n",
    "    startdate = input('Enter start date (YYYYMMDD format): ')\n",
    "    enddate   = input('Enter end date (YYYYMMDD format): ')\n",
    "    LatMin, LatMax, LngMin, LngMax = map(float, input('Enter minLat, maxLat, minLong, maxlong separated by commas: ').split())\n",
    "else:\n",
    "    clear_output(wait = True)\n",
    "    print('Continuing with default specifications...')\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "# The following lines will use the SentinelAPI to download metadata about the available data products for the specified dates and area.\n",
    "# The names of the data product files are stored in satellite_data_filenames.csv \n",
    "# ------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "products_found = s5pdd.getProductList(startdate, enddate, LatMin, LatMax, LngMin, LngMax)\n",
    "s5pdd.saveProductNames(products_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start downloading satellite data. <br>\n",
    "**Note:** Copy the satellite data files in data/L2 folder of the current project repository to avoid re-downloading. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Skip the next code cell after copying the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s5pdd.downloadNewProducts(products_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mapDataProcess\n",
    "import satelliteDataProcess\n",
    "from pickle import load\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_scaler = load(open('models/satellite_data_scaler.pkl', 'rb'))\n",
    "data_compressor = load_model('satellite_data_encoder')\n",
    "model = load(open('models/regressor_forest.pkl', 'rb'))\n",
    "satelliteDataFiles = pd.read_csv('data/functional_data/satellite_data_filenames.csv')\n",
    "sites = pd.read_csv('data/functional_data/Ground_Data_Sites.csv')\n",
    "color_range = pd.read_csv('data/functional_data/color_ranges.csv')\n",
    "color_range['Low'] = color_range.apply(lambda lows: np.array([int(x) for x in lows['Low'].strip('][').split(' ') if x!='']), axis=1)\n",
    "color_range['High'] = color_range.apply(lambda lows: np.array([int(x) for x in lows['High'].strip('][').split(' ') if x!='']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the estimation of NO2, map data is downloaded from OpenStreetMap server to extract land-use data. <br>\n",
    "As multiple time instances will be evaluated for each location, the map data will be reused. To avoid having to repeatedly download the same map data, every new map data will be stored in a dictionary. <br>\n",
    "This can be replicated in a mobile app by saving user data for the most frequent locations - eg. the user's residence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_dict = dict() #dictionary to save land_use data extracted from OpenStreetMap data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO2 Estimation Function\n",
    "The function accepts a latitude, longitude and datetime as input and returns an estimate of the NO2 concentration for the specified time and place in Âµg/m^3. <br>\n",
    "* Dependencies:\n",
    ">* satelliteDataProcess.py <br>\n",
    ">* mapDataProcess.py <br>\n",
    ">* Pandas <br>\n",
    ">* Numpy\n",
    "* Parameters:\n",
    ">* latitude: Latitude of the place of interest <br>\n",
    ">* longitude: Longitude of the place of interest <br>\n",
    ">* datetime: Date and time of when the NO2 estimate is required as a datetime object <br>\n",
    ">* data_files: Iterable list of names of Sentinel5P product files available in data/L2 folder. <br>\n",
    ">* data_compressor: Autoencoder trained to compress the extracted satellite data. <br>\n",
    ">* data_scaler: MinMaxScaler trained to scale the satellite data before encoding. <br>\n",
    ">* color_range: Dataframe containing color ranges to filter out features from OpenStreetMap images.\n",
    ">* model: Trained ML Model for estimating NO2 using satellite and map data.\n",
    "* Returns:\n",
    ">* Estimate of the NO2 concentration as float.<br>\n",
    ">  In case of no estimate, returns None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateNO2(latitude, longitude, datetime, data_files, data_compressor, data_scaler, color_range, model):   \n",
    "    data_NA = 0\n",
    "    try:\n",
    "        sat_data = satelliteDataProcess.getMostRecentSatelliteData((latitude,longitude), datetime, data_files, data_compressor, data_scaler)\n",
    "    except:\n",
    "        data_NA = 1\n",
    "        print('No recent usable satellite data!')\n",
    "        \n",
    "    if(data_NA == 0):\n",
    "        if ((latitude,longitude) in land_use_dict.keys()):\n",
    "            land_use = pd.DataFrame(land_use_dict[(latitude,longitude)]).transpose()\n",
    "            land_use.reset_index(drop=True,inplace=True)\n",
    "        else:\n",
    "            land_use = mapDataProcess.getLandUseTerms((latitude,longitude),color_range,km=7)\n",
    "            land_use.rename(index = {0:(latitude,longitude)}, inplace = True)\n",
    "            land_use_dict.update(dict(land_use.transpose()).items())\n",
    "            land_use.reset_index(drop=True,inplace=True)\n",
    "            \n",
    "        variables = pd.DataFrame({'Latitude':latitude,'Longitude':longitude},index=[0])\n",
    "        variables = pd.concat([variables,sat_data,land_use], axis=1)\n",
    "        variables[['Month','WeekDay','Hour']] = [datetime.month, datetime.weekday(), datetime.hour]\n",
    "        variables = np.array(variables)\n",
    "\n",
    "        return model.predict(variables)[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO2 Estimation\n",
    "This code segment is to be used to get NO2 estimates. <br>\n",
    "_The first estimate may take longer than the one's after for a place depending on Internet speed due to map download._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the latitude of the location:  51.4\n",
      "Enter the longitude of the location:  0.1\n",
      "Enter when to do the estimate (format like: April 4 2021 1:33PM):  April 1 2021 2:45PM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.255498 seconds.\n",
      "\n",
      "NO2 concentration: 10.656 Âµg/m^3\n",
      "Compressed data filesize: 0.12 kB\n"
     ]
    }
   ],
   "source": [
    "latitude = float(input('Enter the latitude of the location: '))\n",
    "longitude = float(input('Enter the longitude of the location: '))\n",
    "datetime = datetime.strptime(input('Enter when to do the estimate (format like: April 4 2021 1:33PM): '), '%B %d %Y %I:%M%p')\n",
    "\n",
    "tic()\n",
    "no2 = estimateNO2(latitude, longitude, datetime, satelliteDataFiles['ProductFiles'], data_compressor, data_scaler, color_range, model)\n",
    "toc()\n",
    "\n",
    "filesize = os.path.getsize('Compressed_Satellite_Data.csv')/1024\n",
    "if(not no2): \n",
    "    print('No estimate.')\n",
    "else:\n",
    "    print('NO2 concentration: %.3f Âµg/m^3'%no2)\n",
    "print('Compressed data filesize: %.2f kB'%filesize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
